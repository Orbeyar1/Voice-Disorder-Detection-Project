The previous project: https://github.com/YiftaChen/VoiceDisorderIdentification

Regarding the sampling rate, less is possible in terms of the range of values we are talking about, but 16KHZ is more accurate and the standard - and we adapt the files to the model. 
In Ginroot Divor, for example, they work with 48KHZ for more accuracy in the values and fewer artifacts.
 
Regarding the splitting of the file, it might also help you to check the SAD alge when you choose what works better in calibration, by and large there are dip-based VADs today,
you need to verify how they are in practice.

הדאטה מורכב מהחלקים הבאים:
אִי טון רגיל
אִי טון נמוך
אִי טון גבוה
אָ טון רגיל
אָ טון נמוך
אָ טון גבוה
אוּ טון רגיל
אוּ טון נמוך
אוּ טון גבוה
הַמממממממ בטון רגיל
רוטב "אלף האיים" הוא רוטב אותו מכינים ממיונז, קטשופ ומגוון של ירקות חתוכים. הרוטב יכול להכיל בצלים, מלפפונים חמוצים, פלפלים, זיתים וביצה קשה.
ניתן להשתמש ברוטב כממרח לכריך או כרוטב לסלט. בשנים האחרונות הפך הרוטב למקובל מאוד ברשתות המזון המהיר. את הרוטב מוסיפים כמעט לכל מאכל, מהמבורגר ועד לסלט.
- אתם תצטרכו לעשות לו resampling ולהפוך אותו ל mono channel: sox זו תוכנה שתעזור לכם בזה).
- החלקים נמצאים באותה הקלטה ואתם תצטרכו למצוא דרך אוטומטית לחתוך את זה (גם לזה sox שימושי)
      השיטות שלדעתי כדאי לבחון ולקרא: VAD(Voice activity detection) ו -sound activity detection.
      הן שיטות די 'רגישות', אבל בהנתן שיש לכם את כמות הקלטות הפלט לאחר החיתוך, יש איזשהו sanity check. אתם יכולים לבדוק כמובן דרכים אחרות.
- אחד היעדים הראשונים בפרויקט זה לבדוק איזה צליל פונטי יותר תורם לאבחון איזו מחלקה.
- בתור התחלה נרצה לאבחן בין בריא לצרוד ולאחר מכן לעבור ללמידה על מולטי-קלאס.
- ולבחון גם האם שימוש במודל הקודם, יכול לשפר את הביצועים.
     
You can check blogs on the subject.
Regarding transformers a good start: https://jalammar.github.io/illustrated-transformer/
https://arxiv.org/abs/2106.07447
If necessary have the previous posts it relies on.

The article in question: https://arxiv.org/abs/2106.07447
If you want, previous works directly related to the article: Discrete BERT and wav2vec2.

In addition, read blogs about audio processing or read speech in the field of ML/deep learning that will cover signal understanding and basic signal processing methods such as STFT and MFCC.
