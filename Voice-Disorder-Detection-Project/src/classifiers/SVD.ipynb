{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"2TboJZbfs-d9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717514690776,"user_tz":-180,"elapsed":29690,"user":{"displayName":"Or Beyar","userId":"10215772442836299100"}},"outputId":"c2ec0b50-d2b3-4d32-90a6-6ab7cd735a4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.0)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.4.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","Requirement already satisfied: import-ipynb in /usr/local/lib/python3.10/dist-packages (0.1.4)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (7.34.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (5.10.4)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (67.7.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.19.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (3.0.45)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.9.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (2.19.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (4.19.2)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (5.7.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.4)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.18.1)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (4.2.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import-ipynb) (0.2.13)\n"]}],"source":["!pip install wandb\n","!pip install import-ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zhViOwyitOP_","collapsed":true},"outputs":[],"source":["\n","from google.colab import drive\n","import import_ipynb\n","import sys\n","\n","drive.mount('/content/drive/',force_remount = False)\n","proj_dir_path = '/content/drive/MyDrive/Study_materials/Voice_disorder_detection_project/'\n","sys.path.append(proj_dir_path)\n","%cd $proj_dir_path\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2r4Cn6GAvd35"},"outputs":[],"source":["from __future__ import print_function, division\n","import os\n","from random import sample\n","# from cv2 import transform\n","import torch\n","import re\n","import glob\n","from torch.utils.data import Dataset\n","from scipy.io import wavfile\n","import torch.nn as nn\n","import pandas as pd\n","# from src.models.yamnet_model import Identity\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import resample\n","\n","from src.transforms.transforms import PadWhiteNoise,ToTensor,Truncate,ToOneHot,WaveformToInput,Inflate,Deflate,CFloat\n","from src.params.params import CommonParams as cfg\n","from src.params.params import Pathologies as PathologiesToIndex\n","from src.params.params import data_location\n","\n","import librosa\n","import random, sys\n","\n","# from torch_audiomentations import Compose, PitchShift,TimeInversion,AddBackgroundNoise\n","from torchaudio.transforms import Spectrogram,TimeStretch, TimeMasking, FrequencyMasking, InverseSpectrogram,GriffinLim\n","import wandb\n","import numpy as np"]},{"cell_type":"code","source":["class patients_dataset:\n","  def __init__(self,audio_files_dir,excel_sheet_path = \"\"):\n","    assert excel_sheet_path, f'No excel sheet path given'\n","    self.excel_path = excel_sheet_path\n","    self.dir = audio_files_dir\n","\n","\n","  def create_binary_labeled_dataset(self):\n","    patients_sheet = pd.read_excel(self.excel_path)\n","    # remove patients with incomplete data within spreadsheet,\n","    # I've taken date of birth column as an indicator\n","    patients_sheet = patients_sheet[patients_sheet['DOB'].notna()]\n","    diagnostics = patients_sheet['dysphonia diagnosis']\n","    # Convert diagnostics to healthy/ill labels\n","    diagnostics = diagnostics.apply(lambda x:0 if x.lower() == 'none' else 1)\n","    db_indices = patients_sheet['#'].to_numpy()\n","    files_array = []\n","    all_patients = glob.glob(self.dir + \"/*.wav\")\n","    all_patients_id = [int(re.findall(r'patient_(\\d+).wav', path.lower())[0]) for path in all_patients]\n","    relevant_patient_ids = np.intersect1d(db_indices,all_patients_id)\n","    files_array = [os.path.join(data_location['preprocessed_data'],'patient_' + str(id))for id in relevant_patient_ids]\n","    self.df = pd.DataFrame({'id':relevant_patient_ids,'filepathway':files_array,'diagnosis':diagnostics})\n","    self.df_size = len(self.df)\n","\n","\n","  def train_val_test_split(self,split =(0.8,0.1,0.1),seed = None):\n","    train_size,val_size,test_size = split\n","    train_size = int(train_size*self.df_size)\n","    val_size = int(val_size*self.df_size)\n","    test_size = self.df_size - train_size - val_size\n","    self.train_set, val_test_sets = train_test_split(self.df,train_size=train_size,test_size=(val_size+test_size),random_state=seed,shuffle=True) #first split into train/ test+val\n","    self.val_set, self.test_set = train_test_split(val_test_sets,train_size=val_size,test_size=test_size,random_state=seed,shuffle=True) #first split into train/ test+val\n","    return self.train_set, self.val_set , self.test_set\n","\n","  def binary_label_up_sample(self,df_to_up, up_amount=1, plot = False):\n","    import matplotlib.pyplot as plt\n","    sick_samples = df_to_up[df_to_up.iloc[:,-1] == 1]\n","    healthy_samples = df_to_up[df_to_up.iloc[:,-1] == 0]\n","    if len(sick_samples) > len(healthy_samples):\n","      majority = sick_samples\n","      minority = healthy_samples\n","    else:\n","      majority = healthy_samples\n","      minority = sick_samples\n","    difference = len(majority) - len(minority)\n","    new_samples = resample(minority,replace=True,n_samples= difference*up_amount,random_state = 0)\n","    new_minority = pd.concat([minority, new_samples])\n","    entire_df = pd.concat([new_minority,majority])\n","    #shuffle new samples into the df\n","    entire_df = entire_df.sample(frac=1).reset_index(drop=True)\n","\n","    if (plot):\n","      print(\"entire df size: \", len(df_to_up))\n","      print(\"Major label size is: \", len(majority))\n","      print(\"Minor label size is: \", len(minority))\n","      print(\"Difference in labels is: \", difference)\n","      print(f\"new minor label size is: {len(minority)}+{len(new_samples)} = {len(new_minority)} \")\n","      print(\"new df size is: \", len(entire_df))\n","      bin = df_to_up.iloc[:,-1].value_counts()\n","      bin_up = entire_df.iloc[:,-1].value_counts()\n","\n","      plt.subplot(1, 2, 1) # row 1, col 2 index 1\n","      bin.plot(kind='bar')\n","      plt.xlabel('1: Sick     0: Healthy')\n","      plt.ylabel('Count')\n","      plt.title('Distribution of patients originally')\n","\n","      plt.subplot(1, 2, 2) # index 2\n","      bin_up.plot(kind='bar')\n","      plt.xlabel('1: Sick     0: Healthy')\n","      plt.ylabel('Count')\n","      plt.title('After upsampling')\n","      plt.show()\n","    return entire_df\n","\n","  def upsample_all_subsets(self,up_amount=1):\n","    try:\n","      self.train_set = self.binary_label_up_sample(df_to_up=self.train_set,up_amount=1, plot = False)\n","      self.val_set = self.binary_label_up_sample(df_to_up=self.val_set,up_amount=1, plot = False)\n","      self.test_set = self.binary_label_up_sample(df_to_up=self.test_set,up_amount=1, plot = False)\n","    except Exception as e:\n","      print(\"Upsampling error: \",e)"],"metadata":{"id":"wDZRRIyEhxTo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qtlmL71uoqqY"},"outputs":[],"source":["def create_transformations(augmentations):\n","    print(augmentations)\n","    name_to_aug = {\n","        \"TimeStretch\":TimeStretch(fixed_rate=0.8),\n","        \"FrequencyMasking\":\n","        FrequencyMasking(\n","            freq_mask_param=80\n","        ),\n","        \"TimeMasking\":\n","            TimeMasking(time_mask_param=80),\n","    }\n","\n","    transforms = [name_to_aug[augmentation] for augmentation in augmentations]\n","    transforms = [Spectrogram()]+ transforms + [CFloat(),InverseSpectrogram()]\n","    return nn.Sequential(*transforms)\n","\n","default_label_transforms = nn.Sequential(ToOneHot())\n","\n","def create_datasets(root_dir,split:tuple,hp,filter_gender=None,seed=None,**kwargs)->list():\n","    assert sum(split)==1, f\"Splits fraction array should sum up to 1\"\n","    split = np.cumsum(split)\n","    files_array = []\n","    if hp[\"filter_gender\"] != None:\n","        root_dir = os.path.join(root_dir,hp[\"filter_gender\"])\n","    for root, dirs, files in os.walk(root_dir):\n","        files_array += [os.path. join(root,f) for f in files if not f.startswith('.') and  f.endswith('.wav')]\n","    if seed == None:\n","        seed = random.randrange(sys.maxsize)\n","    random.Random(seed).shuffle(files_array)\n","    split = [int(s * len(files_array))for s in split][:-1]\n","\n","    files_split = np.split(files_array, split)\n","    hp['seed']=seed\n","    splits = [SvdExtendedVoiceDataset(sp,hp,**kwargs) for sp in files_split]\n","\n","    return splits\n","\n","# TODO: make this inherit AudioFolderDataset\n","class SvdExtendedVoiceDataset(Dataset):\n","    \"\"\"Saarbruken blah blah\"\"\"\n","\n","    def __init__(self, files, hp,label_transform=default_label_transforms, class_definitions=None,classification_binary=True):\n","    # audiomentations = create_transformations(hp['augmentations'])\n","        data_transform = nn.Sequential(ToTensor(),PadWhiteNoise(50000),Truncate(50000))\n","\n","        self.data_transform = data_transform\n","        self.label_transform = label_transform\n","        self.classification_binary = classification_binary\n","        self.class_definitions=class_definitions if class_definitions!= None else PathologiesToIndex# Placeholder for actual definitions\n","        self.seed = hp['seed']\n","        self.files = files\n","            # assert len(files) == 0 or (len(files) != 0 and\n","        assert len(self.files) > 0,f\"Directory should not be empty, it is {self.files}\"\n","\n","    def _load_wav(self,wav_file):\n","        return wavfile.read(wav_file)\n","    def _get_class(self,wav_file_path):\n","        print(\"cd is \",self.class_definitions)\n","        return self.class_definitions[wav_file_path.split('/')[-3]],  wav_file_path.split('/')[-3]\n","    def __len__(self):\n","        return len(self.files)\n","    def __getitem__(self, index):\n","        if torch.is_tensor(index):\n","            index = index.item()\n","        if isinstance(index,list):\n","            index = index[0]\n","        samplerate, data = self._load_wav(self.files[index])\n","        classification_index,classification = self._get_class(self.files[index])\n","\n","        if self.data_transform != None:\n","            data = self.data_transform(data)\n","        if self.label_transform != None and not self.classification_binary:\n","            label = self.label_transform(classification)\n","        if self.classification_binary:\n","            label = classification_index!=0\n","        return {'data':data, 'sampling_rate':samplerate,'classification':label,'original_class':classification}\n","\n","class SvdCutOffShort(SvdExtendedVoiceDataset):\n","    \"\"\"Saarbruken blah blah, cut off samples smaller than 0.96\"\"\"\n","    def __init__(self, files, hp,label_transform=default_label_transforms, class_definitions=None,classification_binary=True,overfit_test = False):\n","        super().__init__(files,hp,label_transform,class_definitions,classification_binary)\n","        import random\n","        self.files = [file for file in self.files if librosa.get_duration(filename=file)>=cfg.VOICE_SAMPLE_MIN_LENGTH]\n","        random.shuffle(self.files)\n","        if overfit_test:\n","            self.files = self.files[:40]\n","\n","\n","class SvdWindowedDataset(SvdExtendedVoiceDataset):\n","    \"\"\"Saarbruken blah blah, cut off samples smaller than 0.96\"\"\"\n","    def __init__(self, files, hp,label_transform=default_label_transforms, class_definitions=None,classification_binary=True,overfit_test = False,delta=1):\n","        super().__init__(files,hp,label_transform,class_definitions,classification_binary)\n","        import random\n","        def _filter_pitch(filename):\n","            if hp[\"filter_pitch\"] != None:\n","                return filename.split(\"_\")[1].split(\".\")[0] in hp[\"filter_pitch\"]\n","            return True\n","        def _filter_sound(filename):\n","            if hp[\"filter_letter\"] != None:\n","                # assert False, f\"filename split {filename.split('_')}\"\n","                return filename.split(\"_\")[0].split(\"-\")[1] in hp[\"filter_letter\"]\n","            return True\n","        self.delta=delta\n","        self.files = [file for file in self.files if _filter_sound(file) and _filter_pitch(file)]\n","        self.files = self._inflate_sound_files(self.files)\n","\n","        if overfit_test:\n","            random.shuffle(self.files)\n","            self.files = self.files[:40]\n","\n","    def _load_wav(self,wav_file):\n","        window_index = wav_file[\"window_index\"]\n","        file_path = wav_file[\"path\"]\n","        sample_rate,data = wavfile.read(file_path)\n","        start_index = int(self.delta*window_index*cfg.SVD_SAMPLE_RATE)\n","        end_index = int(self.delta*(window_index+1)*cfg.SVD_SAMPLE_RATE)\n","        return sample_rate,data[start_index:end_index]\n","    def _get_class(self,wav_file):\n","        wav_file_path = wav_file[\"path\"]\n","        return self.class_definitions[wav_file_path.split('/')[-3]], wav_file_path.split('/')[-3]\n","\n","    def _inflate_sound_files(self,files):\n","        def get_window_count(f):\n","            length = librosa.get_duration(filename=f)*cfg.SVD_SAMPLE_RATE\n","            length = 0 if length-cfg.SVD_SAMPLE_RATE<0 else length-cfg.SVD_SAMPLE_RATE\n","            return int(length/(self.delta*cfg.SVD_SAMPLE_RATE))+1\n","        return [{'path':file,'window_index':i} for file in files for i in range(get_window_count(file))]\n","\n","if __name__ == \"__main__\":\n","    from tqdm import tqdm\n","    from torch.utils.data import DataLoader\n","\n","    hp = {}\n","    hp[\"augmentations\"] = None\n","    hp[\"filter_pitch\"] = None\n","    hp[\"filter_letter\"] = None\n","    hp[\"filter_gender\"] = None\n","\n","    # sets = create_datasets(data_location['preprocessed_data'],split=(0.6,0.2,0.2),hp=hp,filter_gender=None)\n","    sets = patients_dataset(audio_files_dir=data_location[\"preprocessed_data\"],excel_sheet_path = data_location[\"data_spreadsheet\"])\n","    sets.create_binary_labeled_dataset()\n","    sets.train_val_test_split()\n","    sets.upsample_all_subsets()"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMKp0ja4xKZPKTVD753+gFu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}