{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCwkvIcgNOvJ7pcWjMq5gS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install import-ipynb\n","from google.colab import drive\n","import import_ipynb\n","import sys\n","\n","drive.mount('/content/drive/',force_remount = False)\n","proj_dir_path = '/content/drive/MyDrive/Study_materials/Voice_disorder_detection_project/'\n","sys.path.append(proj_dir_path)\n","%cd $proj_dir_path\n"],"metadata":{"id":"6hwYIXauuVKb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from turtle import forward\n","\n","from numpy import inner\n","from src.models.yamnet_model import yamnet\n","import torch\n","import torch.nn as nn\n","import s3prl.hub\n","from transformers import Wav2Vec2Processor, HubertModel\n","import torchaudio.pipelines"],"metadata":{"id":"g1FyWND4uRAk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qi3Cy179uO-m"},"outputs":[],"source":["class YamnetClassifier(nn.Module):\n","    def __init__(self,dimensions=[],out_dim=1,activation=nn.ReLU(),freeze_backend_grad=True) -> None:\n","        super().__init__()\n","        layers = []\n","        input_dim=1024\n","        for dimension in dimensions:\n","            layers += [nn.Linear(input_dim,dimension,bias=False),\n","                        # nn.BatchNorm1d(num_features=dimension),\n","                        activation]\n","            input_dim = dimension\n","        layers+=[nn.Linear(input_dim,out_dim,bias=False)]\n","\n","        self.classifier=nn.Sequential(*layers)\n","        self.backend = yamnet(pretrained=True,remove_orig_classifier=True,freeze_grad=freeze_backend_grad)\n","        self.full_layout = nn.Sequential(self.backend,self.classifier)\n","\n","    def forward(self,x):\n","        return self.full_layout(x).squeeze()\n","\n","class DistilHUBERTClassifier(nn.Module):\n","    def __init__(self,dimensions=[],out_dim=1,activation=nn.GELU(),freeze_backend_grad=True) -> None:\n","        super().__init__()\n","        layers = []\n","        input_dim = 768\n","        input_dim = 156*input_dim\n","\n","        # for dimension in dimensions:\n","        #     layers += [nn.Linear(input_dim,dimension,bias=False),\n","        #                 # nn.BatchNorm1d(num_features=dimension),\n","        #                 activation]\n","        #     input_dim = dimension\n","        layers+=[nn.Linear(input_dim,1280,bias=False),nn.BatchNorm1d(num_features=1280),activation,nn.Linear(1280,out_dim,bias=False)]\n","\n","        self.classifier=nn.Sequential(*layers)\n","        self.backend = s3prl.hub.distilhubert()\n","        if freeze_backend_grad:\n","            for param in self.backend.parameters():\n","                param.requires_grad = False\n","            for param in self.backend.model.model.output_layer.parameters():\n","                param.requires_grad = True\n","            for param in self.backend.model.model.encoder.layers[1].parameters():\n","                param.requires_grad = True\n","            for param in self.backend.model.model.encoder.layers[0].parameters():\n","                param.requires_grad = True\n","\n","        self.full_layout = nn.Sequential(self.backend,self.classifier)\n","\n","    def forward(self,x):\n","        if(len(x)>2):\n","            x=x.squeeze()\n","        x = self.backend(x)['last_hidden_state']\n","        x = x.reshape(x.shape[0],-1)\n","        return self.classifier(x).squeeze()\n","\n","class SinusoidalActivation(nn.Module):\n","    def forward(self,x):\n","        return torch.sin(x)\n","\n","class FullyConnectedClassificationHead(nn.Module):\n","    def __init__(self,input_dim,out_dim,activation=nn.ReLU()):\n","        super().__init__()\n","        layers=[nn.Linear(input_dim,1280,bias=False),nn.BatchNorm1d(num_features=1280),activation,nn.Linear(1280,out_dim,bias=False)]\n","        self.layers = nn.Sequential(*layers)\n","    def forward(self,x):\n","        x = x.reshape(x.shape[0],-1)\n","        return self.layers(x)\n","\n","class ConvolutionalClassificationHead(nn.Module):\n","    def __init__(self,input_dim,out_dim,activation=nn.ReLU(), kernels=[5,5,5]):\n","        super().__init__()\n","        layers = []\n","        inner_dim = [1,1,1]\n","        inp = input_dim\n","        for kernel,in_dim in zip(kernels,inner_dim):\n","            layers += [nn.Conv2d(inp,in_dim,kernel_size=(3,kernel),stride=(1,2)),nn.BatchNorm2d(in_dim),activation]\n","            inp=in_dim\n","        layers_fully_connected = [nn.Linear(3999,512,bias=False),nn.BatchNorm1d(num_features=512),activation,nn.Linear(512,out_dim,bias=False)]\n","        self.layers = nn.Sequential(*layers)\n","        self.layers_fully_connected = nn.Sequential(*layers_fully_connected)\n","    def forward(self,x):\n","        x = x.unsqueeze(-1).reshape(x.shape[0],1,x.shape[1],x.shape[2])\n","        x = self.layers(x)\n","        x = x.reshape(x.shape[0],-1)\n","        return self.layers_fully_connected(x)\n","\n","class Wav2Vec2Classifier(nn.Module):\n","    def __init__(self,dimensions=[],configuration=\"base\",out_dim=1,activation=nn.ReLU(),freeze_backend_grad=True) -> None:\n","        super().__init__()\n","        layers = []\n","        if configuration == \"base\":\n","            input_dim = 768\n","            self.bundle = torchaudio.pipelines.WAV2VEC2_BASE\n","        elif configuration == \"large\":\n","            input_dim = 1024\n","            self.bundle = torchaudio.pipelines.WAV2VEC2_LARGE\n","        self.model = self.bundle.get_model()\n","\n","        # for dimension in dimensions:\n","        #     layers += [nn.Linear(input_dim,dimension,bias=False),\n","        #                 # nn.BatchNorm1d(num_features=dimension),\n","        #                 activation]\n","        #     input_dim = dimension\n","        input_dim = input_dim*49\n","        layers+=[nn.Linear(input_dim,1280,bias=False),nn.BatchNorm1d(num_features=1280),activation,nn.Linear(1280,out_dim,bias=False)]\n","\n","\n","        self.classifier=nn.Sequential(*layers)\n","        # self.backend = s3prl.hub.hubert()\n","        if freeze_backend_grad:\n","            for param in self.model.parameters():\n","                param.requires_grad = False\n","            for param in self.model.encoder.parameters():\n","                param.requires_grad = True\n","            # for param in self.processor.parameters():\n","            #     param.requires_grad = False\n","\n","\n","    def forward(self,x):\n","        x = x.reshape((x.shape[0],x.shape[-1]))\n","        x = torchaudio.functional.resample(x, 50000, self.bundle.sample_rate)\n","        x,y = self.model(x)\n","        x = x.reshape(x.shape[0],-1)\n","        return self.classifier(x).squeeze()\n","\n","class HubertClassifier(nn.Module):\n","    def __init__(self,dimensions=[],configuration=\"base\",out_dim=1,activation=SinusoidalActivation(),freeze_backend_grad=True) -> None:\n","        super().__init__()\n","        layers = []\n","        if configuration == \"base\":\n","            input_dim = 768\n","            self.bundle = torchaudio.pipelines.HUBERT_BASE\n","        elif configuration == \"large\":\n","            input_dim = 1024\n","            self.bundle = torchaudio.pipelines.HUBERT_LARGE\n","        elif configuration == \"xlarge\":\n","            input_dim = 1280\n","            self.bundle = torchaudio.pipelines.HUBERT_XLARGE\n","\n","        self.model = self.bundle.get_model()\n","\n","        # for dimension in dimensions:\n","        #     layers += [nn.Linear(input_dim,dimension,bias=False),\n","        #                 # nn.BatchNorm1d(num_features=dimension),\n","        #                 activation]\n","        #     input_dim = dimension\n","        input_dim = input_dim*49\n","\n","        self.classifier=ConvolutionalClassificationHead(1,out_dim,activation=activation)\n","        # self.backend = s3prl.hub.hubert()\n","        if freeze_backend_grad:\n","            for param in self.model.parameters():\n","                param.requires_grad = False\n","            for param in self.model.encoder.parameters():\n","                param.requires_grad = True\n","            # for param in self.processor.parameters():\n","            #     param.requires_grad = False\n","\n","\n","    def forward(self,x):\n","        x = x.reshape((x.shape[0],x.shape[-1]))\n","        x = torchaudio.functional.resample(x, 50000, self.bundle.sample_rate)\n","        x,y = self.model(x)\n","        # x = self.classifier(x)\n","        # x = x.reshape(x.shape[0],-1)\n","        return self.classifier(x).squeeze()"]}]}