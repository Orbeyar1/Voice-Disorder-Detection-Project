{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1hvfZrPlBFaSLj5VQqiVx4JTxfiqO0DDD","timestamp":1716804960864}],"authorship_tag":"ABX9TyMzfcnxL70BurAJQ04/COoC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["ckpt_url = \"https://github.com/w-hc/torch_audioset/releases/download/v0.1/yamnet.pth\"\n","import torch.nn as nn\n","import os.path as osp\n","import sys\n","import yaml\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import hub\n","\n","\n","print(\"Imported yamnet_model.ipynb\")\n","from google.colab import drive\n","drive.mount('/content/drive/',force_remount = False)\n","proj_dir_path = '/content/drive/MyDrive/Study_materials/Voice_disorder_detection_project/'\n","sys.path.append(proj_dir_path)\n","%cd $proj_dir_path"],"metadata":{"id":"VeHJ7B93i0-A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717512099432,"user_tz":-180,"elapsed":2394,"user":{"displayName":"Or Beyar","userId":"10215772442836299100"}},"outputId":"98cd1f41-805b-4be7-8c1c-04e91a77a6ab"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Imported yamnet_model.ipynb\n","Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/Othercomputers/My MacBook Pro/Study materials/Voice_disorder_detection_project\n"]}]},{"cell_type":"code","execution_count":20,"metadata":{"id":"HlogoZCFixcG","executionInfo":{"status":"ok","timestamp":1717512099432,"user_tz":-180,"elapsed":4,"user":{"displayName":"Or Beyar","userId":"10215772442836299100"}}},"outputs":[],"source":["class YAMNetParams():\n","    # Copyright 2019 The TensorFlow Authors All Rights Reserved.\n","    #\n","    # Licensed under the Apache License, Version 2.0 (the \"License\");\n","    # you may not use this file except in compliance with the License.\n","    # You may obtain a copy of the License at\n","    #\n","    #     http://www.apache.org/licenses/LICENSE-2.0\n","    #\n","    # Unless required by applicable law or agreed to in writing, software\n","    # distributed under the License is distributed on an \"AS IS\" BASIS,\n","    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","    # See the License for the specific language governing permissions and\n","    # limitations under the License.\n","    # ==============================================================================\n","\n","    \"\"\"Hyperparameters for YAMNet.\"\"\"\n","\n","    # The following hyperparameters (except PATCH_HOP_SECONDS) were used to train YAMNet,\n","    # so expect some variability in performance if you change these. The patch hop can\n","    # be changed arbitrarily: a smaller hop should give you more patches from the same\n","    # clip and possibly better performance at a larger computational cost.\n","    SAMPLE_RATE = 16000\n","    STFT_WINDOW_SECONDS = 0.025\n","    STFT_HOP_SECONDS = 0.010\n","    MEL_BANDS = 64\n","    MEL_MIN_HZ = 125\n","    MEL_MAX_HZ = 7500\n","    LOG_OFFSET = 0.001\n","    PATCH_WINDOW_SECONDS = 0.96\n","    PATCH_HOP_SECONDS = 0.48\n","    # PATCH_WINDOW_SECONDS = 0.48\n","    # PATCH_HOP_SECONDS = 0.24\n","    PATCH_FRAMES = int(round(PATCH_WINDOW_SECONDS / STFT_HOP_SECONDS))\n","    PATCH_BANDS = MEL_BANDS\n","    NUM_CLASSES = 521\n","    CONV_PADDING = 'same'\n","    BATCHNORM_CENTER = True\n","    BATCHNORM_SCALE = False\n","    BATCHNORM_EPSILON = 1e-4\n","    CLASSIFIER_ACTIVATION = 'sigmoid'\n","\n","    FEATURES_LAYER_NAME = 'features'\n","    EXAMPLE_PREDICTIONS_LAYER_NAME = 'predictions'\n","\n","\n","# NOTE for our inference, don't need overlapping windows\n","# YAMNetParams.PATCH_HOP_SECONDS = YAMNetParams.PATCH_WINDOW_SECONDS\n","# YAMNetParams.PATCH_HOP_SECONDS = 1.0"]},{"cell_type":"code","source":["__all__ = ['yamnet', 'yamnet_category_metadata']\n","\n","class Conv2d_tf(nn.Conv2d):\n","    \"\"\"\n","    Conv2d with the padding behavior from TF Slim\n","    \"\"\"\n","    def __init__(self, *args, **kwargs):\n","        # remove padding argument to avoid conflict\n","        padding = kwargs.pop(\"padding\", \"SAME\")\n","        # initialize nn.Conv2d\n","        super().__init__(*args, **kwargs)\n","        self.padding = padding\n","        assert self.padding == \"SAME\"\n","        self.num_kernel_dims = 2\n","        self.forward_func = lambda input, padding: F.conv2d(\n","            input, self.weight, self.bias, self.stride,\n","            padding=padding, dilation=self.dilation, groups=self.groups,\n","        )\n","\n","    def tf_SAME_padding(self, input, dim):\n","        input_size = input.size(dim + 2)\n","        filter_size = self.kernel_size[dim]\n","\n","        dilate = self.dilation\n","        dilate = dilate if isinstance(dilate, int) else dilate[dim]\n","        stride = self.stride\n","        stride = stride if isinstance(stride, int) else stride[dim]\n","\n","        effective_kernel_size = (filter_size - 1) * dilate + 1\n","        out_size = (input_size + stride - 1) // stride\n","        total_padding = max(\n","            0, (out_size - 1) * stride + effective_kernel_size - input_size\n","        )\n","        total_odd = int(total_padding % 2 != 0)\n","        return total_odd, total_padding\n","\n","    def forward(self, input):\n","        if self.padding == \"VALID\":\n","            return self.forward_func(input, padding=0)\n","        odd_1, padding_1 = self.tf_SAME_padding(input, dim=0)\n","        odd_2, padding_2 = self.tf_SAME_padding(input, dim=1)\n","        if odd_1 or odd_2:\n","            # NOTE: F.pad argument goes from last to first dim\n","            input = F.pad(input, [0, odd_2, 0, odd_1])\n","\n","        return self.forward_func(\n","            input, padding=[ padding_1 // 2, padding_2 // 2 ]\n","        )\n","\n","\n","class CONV_BN_RELU(nn.Module):\n","    def __init__(self, conv):\n","        super().__init__()\n","        self.conv = conv\n","        self.bn = nn.BatchNorm2d(\n","            conv.out_channels, eps=YAMNetParams.BATCHNORM_EPSILON\n","        )  # NOTE: yamnet uses an eps of 1e-4. This causes a huge difference\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        x = self.relu(x)\n","        return x\n","\n","\n","class Conv(nn.Module):\n","    def __init__(self, kernel, stride, input_dim, output_dim):\n","        super().__init__()\n","        self.fused = CONV_BN_RELU(\n","            Conv2d_tf(\n","                in_channels=input_dim, out_channels=output_dim,\n","                kernel_size=kernel, stride=stride,\n","                padding='SAME', bias=False\n","            )\n","        )\n","\n","    def forward(self, x):\n","        return self.fused(x)\n","\n","\n","class SeparableConv(nn.Module):\n","    def __init__(self, kernel, stride, input_dim, output_dim):\n","        super().__init__()\n","        self.depthwise_conv = CONV_BN_RELU(\n","            Conv2d_tf(\n","                in_channels=input_dim, out_channels=input_dim, groups=input_dim,\n","                kernel_size=kernel, stride=stride,\n","                padding='SAME', bias=False,\n","            ),\n","        )\n","        self.pointwise_conv = CONV_BN_RELU(\n","            Conv2d_tf(\n","                in_channels=input_dim, out_channels=output_dim,\n","                kernel_size=1, stride=1,\n","                padding='SAME', bias=False,\n","            ),\n","        )\n","\n","    def forward(self, x):\n","        x = self.depthwise_conv(x)\n","        x = self.pointwise_conv(x)\n","        return x\n","\n","class Identity(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x\n","\n","class YAMNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        net_configs = [\n","            # (layer_function, kernel, stride, num_filters)\n","            (Conv,          [3, 3], 2,   32),\n","            (SeparableConv, [3, 3], 1,   64),\n","            (SeparableConv, [3, 3], 2,  128),\n","            (SeparableConv, [3, 3], 1,  128),\n","            (SeparableConv, [3, 3], 2,  256),\n","            (SeparableConv, [3, 3], 1,  256),\n","            (SeparableConv, [3, 3], 2,  512),\n","            (SeparableConv, [3, 3], 1,  512),\n","            (SeparableConv, [3, 3], 1,  512),\n","            (SeparableConv, [3, 3], 1,  512),\n","            (SeparableConv, [3, 3], 1,  512),\n","            (SeparableConv, [3, 3], 1,  512),\n","            (SeparableConv, [3, 3], 2, 1024),\n","            (SeparableConv, [3, 3], 1, 1024)\n","        ]\n","\n","        input_dim = 1\n","        self.layer_names = []\n","        for (i, (layer_mod, kernel, stride, output_dim)) in enumerate(net_configs):\n","            name = 'layer{}'.format(i + 1)\n","            self.add_module(name, layer_mod(kernel, stride, input_dim, output_dim))\n","            input_dim = output_dim\n","            self.layer_names.append(name)\n","\n","        self.classifier = nn.Linear(input_dim, 521, bias=True)\n","\n","    def forward(self, x, to_prob=False):\n","        for name in self.layer_names:\n","            mod = getattr(self, name)\n","            x = mod(x)\n","        x = F.adaptive_avg_pool2d(x, 1)\n","        x = x.reshape(x.shape[0], -1)\n","        x = self.classifier(x)\n","        if to_prob:\n","            x = torch.sigmoid(x)\n","        return x\n","\n","\n","\n","\n","def yamnet(pretrained=True,remove_orig_classifier=True,freeze_grad=True):\n","    model = YAMNet()\n","    if pretrained:\n","        state_dict = hub.load_state_dict_from_url(ckpt_url, progress=True)\n","        model.load_state_dict(state_dict)\n","        if (freeze_grad):\n","            for param in model.parameters():\n","                param.requires_grad = False\n","\n","    if remove_orig_classifier:\n","        model.classifier = Identity()\n","\n","    return model\n","\n","\n","def yamnet_category_metadata():\n","    cat_meta_file = osp.join(proj_dir_path,'src/models/yamnet_category_meta.yml')\n","    with open(cat_meta_file) as f:\n","        cat_meta = yaml.safe_load(f)\n","    return cat_meta"],"metadata":{"id":"4eBqY13ai1bI","executionInfo":{"status":"ok","timestamp":1717512242817,"user_tz":-180,"elapsed":290,"user":{"displayName":"Or Beyar","userId":"10215772442836299100"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class YamnetClassifier(nn.Module):\n","    def __init__(self,dimensions=[],out_dim=1,activation=nn.ReLU(),freeze_backend_grad=True) -> None:\n","        super().__init__()\n","        layers = []\n","        input_dim=1024\n","        for dimension in dimensions:\n","            layers += [nn.Linear(input_dim,dimension,bias=False),\n","                        # nn.BatchNorm1d(num_features=dimension),\n","                        activation]\n","            input_dim = dimension\n","        layers+=[nn.Linear(input_dim,out_dim,bias=False)]\n","\n","        self.classifier=nn.Sequential(*layers)\n","        self.backend = yamnet(pretrained=True,remove_orig_classifier=True,freeze_grad=freeze_backend_grad)\n","        self.full_layout = nn.Sequential(self.backend,self.classifier)\n","\n","    def forward(self,x):\n","        return self.full_layout(x).squeeze()"],"metadata":{"id":"CNzgnGZIi7XO","executionInfo":{"status":"ok","timestamp":1717512103546,"user_tz":-180,"elapsed":273,"user":{"displayName":"Or Beyar","userId":"10215772442836299100"}}},"execution_count":21,"outputs":[]}]}